{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **All Folders Directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bioprospector', 'MDScan', 'MotifSampler', 'Streme', 'MEME']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direcrory_of_folders = 'Results/'\n",
    "folders = [folder for folder in os.listdir(direcrory_of_folders) if os.path.isdir(os.path.join(direcrory_of_folders, folder))]\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_the_files(path):\n",
    "    txt_files = [file for file in os.listdir(path) if file.endswith(\".txt\")]\n",
    "    only_results = []\n",
    "    for file in txt_files:\n",
    "        if '_' in file:\n",
    "            name_parts = file.split(\"_\")\n",
    "            if len(name_parts) > 1:\n",
    "                name = name_parts[0]\n",
    "                only_results.append(name)\n",
    "    name_counts = Counter(only_results)\n",
    "    unique_names = [name for name, count in name_counts.items() if count > 1] \n",
    "    return  unique_names "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **For MDScan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the MDscan output file\n",
    "# with open('Results/MDScan/Ada_1.txt', 'r') as file:\n",
    "#     mdscan_output = file.read()\n",
    "directory_of_files = 'Results/MDScan/'\n",
    "\n",
    "# Extract the motifs using regex\n",
    "motif_pattern = r\"Motif\\s+(\\d+):\\s+Wid\\s+(\\d+);\\s+Score\\s+([\\d.]+);\\s+Sites\\s+(\\d+);\\s+Con\\s+([ACGT]+);\\s+RCon\\s+([ACGT]+)\"\n",
    "# motif_info = re.findall(motif_pattern, mdscan_output)\n",
    "\n",
    "# Extract the site information using regex\n",
    "site_pattern = r\">(\\d+-\\d+-(?:forward|reverse))\\s+Len\\s+\\d+\\s+Site\\s+#(\\d+)\\s+([fr])\\s+(\\d+)\\n([ACGT]+)\"\n",
    "# site_info = re.findall(site_pattern, mdscan_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The return_the_files function stores all the unique names of the .txt files except the background.txt file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The get_the_motifs and get_site_info functions creates a dataframes with vital informations of the motif_info's and the site_info's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_the_motifs_MD(motif_info, file_name):\n",
    "    motifs = {}\n",
    "\n",
    "    for motif_match in motif_info:\n",
    "        motif = {\n",
    "            'File_name': file_name,\n",
    "            'Motif_ID': motif_match[0],\n",
    "            'Width': motif_match[1],\n",
    "            'Score': motif_match[2],\n",
    "            'Sites': motif_match[3],\n",
    "            'con': motif_match[4],\n",
    "            'rcon': motif_match[5]\n",
    "        }\n",
    "        motif_id = motif_match[0]\n",
    "\n",
    "        if motif_id in motifs:\n",
    "            motifs[motif_id].update(motif)  # Merge with existing motif dictionary\n",
    "        else:\n",
    "            motifs[motif_id] = motif\n",
    "\n",
    "    # Convert the motifs dictionary into a DataFrame\n",
    "    df = pd.DataFrame.from_dict(motifs, orient='index')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_site_info(site_info, motif_info, file_name):\n",
    "    data = []\n",
    "    motif_id = 0  # Initial motif ID\n",
    "    initial_position = site_info[0][0]  # Initial position\n",
    "\n",
    "    for site in site_info:\n",
    "        site_id, site_number, _, starting_point, motif_sequence = site\n",
    "\n",
    "        if site_number == '1' and site_id == initial_position:\n",
    "            motif_id += 1\n",
    "            # initial_position = site_id\n",
    "\n",
    "        data.append([site_id, site_number, starting_point, motif_sequence, motif_id, file_name])\n",
    "\n",
    "    columns = ['Site_ID', 'Site_number', 'Starting_Point', 'Motif_Sequence', 'Motif_ID', 'File_Name']\n",
    "    df_info = pd.DataFrame(data, columns=columns)\n",
    "    return df_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mdscan_output(directory_of_files):\n",
    "    names = return_the_files(directory_of_files)\n",
    "    motif_dfs = []\n",
    "    site_dfs = []\n",
    "\n",
    "    for name in names:\n",
    "        file_paths = [file for file in os.listdir(directory_of_files) if file.startswith(f\"{name}_\")]\n",
    "\n",
    "        for file_path in file_paths:\n",
    "            with open(os.path.join(directory_of_files, file_path), 'r') as file:\n",
    "                mdscan_output = file.read()\n",
    "            \n",
    "            motif_info = re.findall(motif_pattern, mdscan_output)\n",
    "            df_motif = get_the_motifs_MD(motif_info, name)\n",
    "            motif_dfs.append(df_motif)\n",
    "            \n",
    "            site_info = re.findall(site_pattern, mdscan_output)\n",
    "            df_site = get_site_info(site_info, motif_info, name)\n",
    "            site_dfs.append(df_site)\n",
    "\n",
    "    motif_df = pd.concat(motif_dfs, ignore_index=True)\n",
    "    site_df = pd.concat(site_dfs, ignore_index=True)\n",
    "    \n",
    "    site_df['Site_number'] = pd.to_numeric(site_df['Site_number'])\n",
    "    site_df['Motif_ID'] = pd.to_numeric(site_df['Motif_ID'])\n",
    "    site_df['Starting_Point'] = pd.to_numeric(site_df['Starting_Point'])\n",
    "    motif_df['Motif_ID'] = pd.to_numeric(motif_df['Motif_ID'])\n",
    "    motif_df['Sites'] = pd.to_numeric(motif_df['Sites'])\n",
    "    motif_df['Score'] = pd.to_numeric(motif_df['Score'])\n",
    "    motif_df['Width'] = pd.to_numeric(motif_df['Width'])\n",
    "    \n",
    "    return motif_df, site_df\n",
    "\n",
    "# Usage example\n",
    "motif_df_MD, site_df_MD = process_mdscan_output(directory_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_name</th>\n",
       "      <th>Motif_ID</th>\n",
       "      <th>Width</th>\n",
       "      <th>Score</th>\n",
       "      <th>Sites</th>\n",
       "      <th>con</th>\n",
       "      <th>rcon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ada</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1.795</td>\n",
       "      <td>14</td>\n",
       "      <td>CGGAACCGCTGGCGG</td>\n",
       "      <td>CCGCCAGCGGTTCCG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ada</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1.777</td>\n",
       "      <td>16</td>\n",
       "      <td>CCGGAAACGATGGCG</td>\n",
       "      <td>CGCCATCGTTTCCGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ada</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>1.764</td>\n",
       "      <td>16</td>\n",
       "      <td>GGAAGCGCTGGCGGC</td>\n",
       "      <td>GCCGCCAGCGCTTCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ada</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>1.754</td>\n",
       "      <td>19</td>\n",
       "      <td>CGCCGCTGGCGGCTG</td>\n",
       "      <td>CAGCCGCCAGCGGCG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ada</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>1.749</td>\n",
       "      <td>15</td>\n",
       "      <td>TATCCGTGACGGTGA</td>\n",
       "      <td>TCACCGTCACGGATA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  File_name  Motif_ID  Width  Score  Sites              con             rcon\n",
       "0       Ada         1     15  1.795     14  CGGAACCGCTGGCGG  CCGCCAGCGGTTCCG\n",
       "1       Ada         2     15  1.777     16  CCGGAAACGATGGCG  CGCCATCGTTTCCGG\n",
       "2       Ada         3     15  1.764     16  GGAAGCGCTGGCGGC  GCCGCCAGCGCTTCC\n",
       "3       Ada         4     15  1.754     19  CGCCGCTGGCGGCTG  CAGCCGCCAGCGGCG\n",
       "4       Ada         5     15  1.749     15  TATCCGTGACGGTGA  TCACCGTCACGGATA"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motif_df_MD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site_ID</th>\n",
       "      <th>Site_number</th>\n",
       "      <th>Starting_Point</th>\n",
       "      <th>Motif_Sequence</th>\n",
       "      <th>Motif_ID</th>\n",
       "      <th>File_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>209398-209425-forward</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>AAGCGCCGCTGGCGG</td>\n",
       "      <td>1</td>\n",
       "      <td>Ada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>209398-209425-forward</td>\n",
       "      <td>2</td>\n",
       "      <td>258</td>\n",
       "      <td>CGCCATCGCTTCCGG</td>\n",
       "      <td>1</td>\n",
       "      <td>Ada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>209398-209425-forward</td>\n",
       "      <td>3</td>\n",
       "      <td>166</td>\n",
       "      <td>CTGAAGCGATGGGTA</td>\n",
       "      <td>1</td>\n",
       "      <td>Ada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>209398-209425-forward</td>\n",
       "      <td>4</td>\n",
       "      <td>229</td>\n",
       "      <td>CGGAACCACTGGGTG</td>\n",
       "      <td>1</td>\n",
       "      <td>Ada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>209398-209425-forward</td>\n",
       "      <td>5</td>\n",
       "      <td>259</td>\n",
       "      <td>CGGAAGCGATGGCGG</td>\n",
       "      <td>1</td>\n",
       "      <td>Ada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Site_ID  Site_number  Starting_Point   Motif_Sequence  \\\n",
       "0  209398-209425-forward            1             151  AAGCGCCGCTGGCGG   \n",
       "1  209398-209425-forward            2             258  CGCCATCGCTTCCGG   \n",
       "2  209398-209425-forward            3             166  CTGAAGCGATGGGTA   \n",
       "3  209398-209425-forward            4             229  CGGAACCACTGGGTG   \n",
       "4  209398-209425-forward            5             259  CGGAAGCGATGGCGG   \n",
       "\n",
       "   Motif_ID File_Name  \n",
       "0         1       Ada  \n",
       "1         1       Ada  \n",
       "2         1       Ada  \n",
       "3         1       Ada  \n",
       "4         1       Ada  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_df_MD.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **For Bioprospector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bioproepector_path = 'Results/Bioprospector/'  # Replace with the actual directory path\n",
    "motif_pattern = r'Motif\\s+#(\\d+):\\s+\\((\\w+/\\w+)\\)\\n\\*+\\nWidth \\((\\d+), \\d+\\);\\s+Gap \\[\\d+, \\d+\\];\\s+MotifScore (\\d+\\.\\d+);\\s+Sites (\\d+)'\n",
    "site_pattern = r'>(\\d+-\\d+-\\w+)\\s+len\\s\\d+\\s+site\\s+#(\\d+)\\s+(\\w+)\\s+(\\d+)\\n(\\w+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_the_motifs_BP(motif_info, file_name):\n",
    "    motifs = {}\n",
    "\n",
    "    for motif_match in motif_info:\n",
    "        motif_id = motif_match[0]\n",
    "        con, rcon = motif_match[1].split('/')\n",
    "        width = motif_match[2]\n",
    "        score = motif_match[3]\n",
    "        sites = motif_match[4]\n",
    "\n",
    "        motif = {\n",
    "            'File_name': file_name,\n",
    "            'Motif_ID': motif_id,\n",
    "            'Width': width,\n",
    "            'Score': score,\n",
    "            'Sites': sites,\n",
    "            'con': con,\n",
    "            'rcon': rcon\n",
    "        }\n",
    "\n",
    "        if motif_id in motifs:\n",
    "            motifs[motif_id].update(motif)  # Merge with existing motif dictionary\n",
    "        else:\n",
    "            motifs[motif_id] = motif\n",
    "\n",
    "    # Convert the motifs dictionary into a DataFrame\n",
    "    df = pd.DataFrame.from_dict(motifs, orient='index')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_Bioprospector_output(directory_of_files):\n",
    "    names = return_the_files(directory_of_files)\n",
    "    motif_dfs = []\n",
    "    site_dfs = []\n",
    "\n",
    "    for name in names:\n",
    "        file_paths = [file for file in os.listdir(directory_of_files) if file.startswith(f\"{name}_\")]\n",
    "\n",
    "        for file_path in file_paths:\n",
    "            with open(os.path.join(directory_of_files, file_path), 'r') as file:\n",
    "                mdscan_output = file.read()\n",
    "            \n",
    "            motif_info = re.findall(motif_pattern, mdscan_output)\n",
    "            df_motif = get_the_motifs_BP(motif_info, name)\n",
    "            motif_dfs.append(df_motif)\n",
    "            \n",
    "            site_info = re.findall(site_pattern, mdscan_output)\n",
    "            df_site = get_site_info(site_info, motif_info, name)\n",
    "            site_dfs.append(df_site)\n",
    "\n",
    "    motif_df = pd.concat(motif_dfs, ignore_index=True)\n",
    "    site_df = pd.concat(site_dfs, ignore_index=True)\n",
    "    \n",
    "    site_df['Site_number'] = pd.to_numeric(site_df['Site_number'])\n",
    "    site_df['Motif_ID'] = pd.to_numeric(site_df['Motif_ID'])\n",
    "    site_df['Starting_Point'] = pd.to_numeric(site_df['Starting_Point'])\n",
    "    motif_df['Motif_ID'] = pd.to_numeric(motif_df['Motif_ID'])\n",
    "    motif_df['Sites'] = pd.to_numeric(motif_df['Sites'])\n",
    "    motif_df['Score'] = pd.to_numeric(motif_df['Score'])\n",
    "    motif_df['Width'] = pd.to_numeric(motif_df['Width'])\n",
    "    \n",
    "    return motif_df, site_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_df_BP, site_df_BP = process_Bioprospector_output(Bioproepector_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **For MotifSampler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Results/MotifSampler/Ada_1.txt', 'r') as file:\n",
    "    text = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the patterns\n",
    "pattern_id_ll = re.compile(r'^#id: (?P<id>\\S+).*ll: (?P<ll>\\S+)')\n",
    "pattern_sites = re.compile(r'id \"(?P<id>\\S+)\"; site \"(?P<site>\\S+)\";')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: box_1_1_nnTnTnnGTGAnGGT, ll: 28.81, sites: ['GTTATCGGTGAAGGT', 'GGTATCCGTGACGGT', 'TTTTTGCGTGATGGT']\n",
      "id: box_1_2_TCACCGTCACssrkA, ll: 25.89, sites: ['TCACCGTAACCCGGA', 'CCACCTTCACCGATA', 'TTACCGTCACGCATG', 'TCACCGGCATGGGGA']\n",
      "id: box_2_3_TAAmskTTATnCTGA, ll: 28.52, sites: ['TAACGTTTATGCTGA', 'TAAACGTTATTCAGA', 'TAAAGGCTATCCTTA', 'TAGCCTTTAGGCTGC']\n",
      "id: box_3_1_GnTnnCnGnGAnGGn, ll: 28.9, sites: ['GTTATCGGTGAAGGT', 'GGTATCCGTGACGGT', 'GTTCGCCGGGAAGGG']\n",
      "id: box_3_2_AAnnnnGnCGnCnAA, ll: 26.91, sites: ['AAGAGCGCCGACAAA', 'AATGCCGACGGCGAA', 'AAGACGGACGGCAAA']\n",
      "id: box_5_1_kyTTCGyTnTCArCG, ll: 25.01, sites: ['TCGTCGTTATCAGCG', 'GTTGCGCTTTCAACG', 'GCTTCCTTGTCAGCG', 'TTTTCGCTGACAAGG']\n",
      "id: box_5_2_TnysCGTGmCGGTGA, ll: 27.75, sites: ['TCCCCATGCCGGTGA', 'CATGCGTGACGGTAA', 'TATCCGTGACGGTGA', 'TACTCGGGCCGGAGA', 'TTTGCGTGATGGTGA']\n",
      "id: box_5_3_TAAmskTTATnCTGA, ll: 28.5, sites: ['TAACGTTTATGCTGA', 'TAAACGTTATTCAGA', 'TAAAGGCTATCCTTA', 'TAGCCTTTAGGCTGC']\n"
     ]
    }
   ],
   "source": [
    "# Initialize the dictionary to store the results\n",
    "data = {}\n",
    "\n",
    "# Split the text into lines and process each line\n",
    "for line in text.split('\\n'):\n",
    "    match_id_ll = pattern_id_ll.match(line)\n",
    "    match_sites = pattern_sites.search(line)\n",
    "\n",
    "    # If the line matches the id_ll pattern, store the id and ll in the dictionary\n",
    "    if match_id_ll:\n",
    "        id = match_id_ll.group('id')\n",
    "        ll = float(match_id_ll.group('ll'))\n",
    "        data[id] = {'ll': ll, 'sites': []}\n",
    "\n",
    "    # If the line matches the sites pattern, append the site to the list of sites for the appropriate id\n",
    "    if match_sites:\n",
    "        id = match_sites.group('id')\n",
    "        site = match_sites.group('site')\n",
    "        data[id]['sites'].append(site)\n",
    "\n",
    "# Print the results\n",
    "for id, info in data.items():\n",
    "    print(f\"id: {id}, ll: {info['ll']}, sites: {info['sites']}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## **For MEME**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open('Results/MEME/Ada_meme0.txt', 'r') as file:\n",
    "    meme_output = file.read()\n",
    "\n",
    "\n",
    "meme_motif_pattern = r'MOTIF\\s+(?P<motif>\\w+)\\s+MEME-(?P<index>\\d)\\s+width\\s+=\\s+(?P<width>\\d+)\\s+sites\\s+=\\s+(?P<sites>\\d+).+E-value\\s*=\\s*(?P<evalue>\\d+(?:\\.\\d+)?(?:e[+-]?\\d+)?)'\n",
    "meme_motif_info = re.finditer(meme_motif_pattern, meme_output)\n",
    "\n",
    "sites_pattern = r'MEME-(\\d+) sites sorted by position p-value\\n(?:.*\\n){3}((?:(?!-+).*\\n)*)'\n",
    "meme_sites = re.findall(sites_pattern, meme_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'File_name': ['Ada', 'Ada', 'Ada', 'Ada', 'Ada'], 'Motif_ID': [1, 2, 3, 4, 5], 'Width': [8, 8, 10, 8, 9], 'Score': [1.3, 920.0, 10000.0, 18000.0, 13000.0], 'Sites': [15, 11, 2, 2, 3], 'con': ['TCTSGCSG', 'TGAAARMG', 'AGMTTTAAAA', 'TACGGTTA', 'GTGAHGGTG']}\n"
     ]
    }
   ],
   "source": [
    "meme_dict = {'File_name': [],\n",
    "             'Motif_ID': [],\n",
    "             'Width': [],\n",
    "             'Score': [],\n",
    "             'Sites': [],\n",
    "             'con': []\n",
    "             }\n",
    "for i, match in enumerate(meme_motif_info):\n",
    "    # print(match)\n",
    "    meme_dict['File_name'].append('Ada')\n",
    "    meme_dict['Motif_ID'].append(int(match.group('index')))\n",
    "    meme_dict['Width'].append(int(match.group('width')))\n",
    "    meme_dict['Score'].append(float(match.group('evalue')))\n",
    "    meme_dict['Sites'].append(int(match.group('sites')))\n",
    "    meme_dict['con'].append(match.group('motif'))\n",
    "\n",
    "print(meme_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "  File_name  Motif_ID  Width    Score  Sites         con\n3       Ada         4      8  18000.0      2    TACGGTTA\n4       Ada         5      9  13000.0      3   GTGAHGGTG\n2       Ada         3     10  10000.0      2  AGMTTTAAAA\n1       Ada         2      8    920.0     11    TGAAARMG\n0       Ada         1      8      1.3     15    TCTSGCSG",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>File_name</th>\n      <th>Motif_ID</th>\n      <th>Width</th>\n      <th>Score</th>\n      <th>Sites</th>\n      <th>con</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>3</th>\n      <td>Ada</td>\n      <td>4</td>\n      <td>8</td>\n      <td>18000.0</td>\n      <td>2</td>\n      <td>TACGGTTA</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ada</td>\n      <td>5</td>\n      <td>9</td>\n      <td>13000.0</td>\n      <td>3</td>\n      <td>GTGAHGGTG</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Ada</td>\n      <td>3</td>\n      <td>10</td>\n      <td>10000.0</td>\n      <td>2</td>\n      <td>AGMTTTAAAA</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ada</td>\n      <td>2</td>\n      <td>8</td>\n      <td>920.0</td>\n      <td>11</td>\n      <td>TGAAARMG</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>Ada</td>\n      <td>1</td>\n      <td>8</td>\n      <td>1.3</td>\n      <td>15</td>\n      <td>TCTSGCSG</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meme_motif_df = pd.DataFrame(meme_dict)\n",
    "meme_motif_df.sort_values(axis=0, by='Score', inplace=True, ascending=False)\n",
    "meme_motif_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "209398-209425-forward       302  1.61e-05 TGCTGGCGGA TCTGGCCG ATCTCGACGT\n",
      "2145603-2145630-reverse     322  3.22e-05 TGTTGGGATT TCTCGCCG CCCGTGCGGT\n",
      "209398-209425-forward       106  3.22e-05 TATTCCGTTA TCTCGCCG GAAGGTTGTG\n",
      "2145603-2145630-reverse     382  4.82e-05 ATGCCCGTAG TCTGGCGG TGGGCGAATA\n",
      "209398-209425-forward        36  4.82e-05 TGAAGGTGGT TCTGGCGG TGCGCTGGCG\n",
      "2308475-2308502-reverse     398  1.29e-04 TTGCCGTCCG TCTTGCCG CGCCAGACAT\n",
      "2308475-2308502-reverse     361  1.44e-04 GCGAATTCGT TTTCGCCG TGCGTACCAC\n",
      "2308475-2308502-reverse     111  1.61e-04 GCCGGGAAGG GCTGGCGG TTTATATGAT\n",
      "209398-209425-forward       293  1.61e-04 AAGCGCAACT GCTGGCGG ATCTGGCCGA\n",
      "209398-209425-forward       158  1.61e-04 ACAAAGCGCC GCTGGCGG CTGAAGCGAT\n",
      "2308475-2308502-reverse     386  3.02e-04 CACAGGCATC TTTTGCCG TCCGTCTTGC\n",
      "2308475-2308502-reverse      97  3.02e-04 TAAAGAGGTT GTTCGCCG GGAAGGGCTG\n",
      "2308475-2308502-reverse      71  3.82e-04 TTGATGGTAC TCGGGCCG GAGAAAGCTA\n",
      "209398-209425-forward       311  4.13e-04 ATCTGGCCGA TCTCGACG TGTTAAGCAC\n",
      "2145603-2145630-reverse     398  4.76e-04 GGTGGGCGAA TATCGCGG CGTGGTGACT\n",
      "\n",
      "<callable_iterator object at 0x7ff045a367c0>\n",
      "2\n",
      "2145603-2145630-reverse     243  2.97e-05 ACGTTTATGC TGAAAGCG GATGAATAAG\n",
      "209398-209425-forward       280  2.97e-05 GCGGCATCGT TGAAAGCG CAACTGCTGG\n",
      "209398-209425-forward       397  4.38e-05 GCAAAAGTTC TGAAAAAG GGTCACTTCG\n",
      "209398-209425-forward       196  7.27e-05 GCTCCGCGTC TGAAAGAA CTGAAACTGA\n",
      "2145603-2145630-reverse     207  8.73e-05 AACCGGAATA TGAAAGCA AAGCGCAGCG\n",
      "2308475-2308502-reverse     279  1.15e-04 GAGCTGATTA TGAAAAAA GCCACATGCT\n",
      "209398-209425-forward       135  1.30e-04 GTCCATTCTG TGGAAGAG CGCCGACAAA\n",
      "2308475-2308502-reverse     201  1.59e-04 GCGAAAAAAA TTAAAGCG CAAGATTGTT\n",
      "2145603-2145630-reverse     348  2.76e-04 GTGAGCAGTG TGGAAACG GTCGCGGACA\n",
      "2145603-2145630-reverse     253  3.65e-04 TGAAAGCGGA TGAATAAG GAGATGCGAT\n",
      "2308475-2308502-reverse      86  6.39e-04 CCGGAGAAAG CTAAAGAG GTTGTTCGCC\n",
      "\n",
      "<callable_iterator object at 0x7ff045a36970>\n",
      "3\n",
      "209398-209425-forward       332  8.35e-07 TAAGCACTGA AGATTTAAAA AATCGTCGTT\n",
      "2308475-2308502-reverse     145  1.70e-06 AGAAGGCGAT AGCTTTAAAA CCTGGATGTC\n",
      "\n",
      "<callable_iterator object at 0x7ff045a364c0>\n",
      "4\n",
      "209398-209425-forward       369  1.46e-05 CCTGATGAGC TACGGTTA CGCGTAATTC\n",
      "209398-209425-forward        14  1.46e-05 CGGTAGTTTG TACGGTTA TCGGTGAAGG\n",
      "\n",
      "<callable_iterator object at 0x7ff045a28340>\n",
      "5\n",
      "2308475-2308502-reverse     228  7.59e-06 TGGTTTTTGC GTGATGGTG ACCGGGCAGC\n",
      "209398-209425-forward        25  7.59e-06 ACGGTTATCG GTGAAGGTG GTTCTGGCGG\n",
      "2308475-2308502-reverse      10  1.15e-05  CTGGTATCC GTGACGGTG ATTGCTCCGA\n",
      "\n",
      "<callable_iterator object at 0x7ff0459d4a30>\n",
      "{'Site_ID': ['209398-209425-forward', '2145603-2145630-reverse', '209398-209425-forward', '2145603-2145630-reverse', '209398-209425-forward', '2308475-2308502-reverse', '2308475-2308502-reverse', '2308475-2308502-reverse', '209398-209425-forward', '209398-209425-forward', '2308475-2308502-reverse', '2308475-2308502-reverse', '2308475-2308502-reverse', '209398-209425-forward', '2145603-2145630-reverse', '2145603-2145630-reverse', '209398-209425-forward', '209398-209425-forward', '209398-209425-forward', '2145603-2145630-reverse', '2308475-2308502-reverse', '209398-209425-forward', '2308475-2308502-reverse', '2145603-2145630-reverse', '2145603-2145630-reverse', '2308475-2308502-reverse', '209398-209425-forward', '2308475-2308502-reverse', '209398-209425-forward', '209398-209425-forward', '2308475-2308502-reverse', '209398-209425-forward', '2308475-2308502-reverse'], 'Site_number': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 1, 0, 1, 0, 1, 2], 'Starting_Point': [302, 322, 106, 382, 36, 398, 361, 111, 293, 158, 386, 97, 71, 311, 398, 243, 280, 397, 196, 207, 279, 135, 201, 348, 253, 86, 332, 145, 369, 14, 228, 25, 10], 'Motif_Sequence': ['TGCTGGCGGA', 'TGTTGGGATT', 'TATTCCGTTA', 'ATGCCCGTAG', 'TGAAGGTGGT', 'TTGCCGTCCG', 'GCGAATTCGT', 'GCCGGGAAGG', 'AAGCGCAACT', 'ACAAAGCGCC', 'CACAGGCATC', 'TAAAGAGGTT', 'TTGATGGTAC', 'ATCTGGCCGA', 'GGTGGGCGAA', 'ACGTTTATGC', 'GCGGCATCGT', 'GCAAAAGTTC', 'GCTCCGCGTC', 'AACCGGAATA', 'GAGCTGATTA', 'GTCCATTCTG', 'GCGAAAAAAA', 'GTGAGCAGTG', 'TGAAAGCGGA', 'CCGGAGAAAG', 'TAAGCACTGA', 'AGAAGGCGAT', 'CCTGATGAGC', 'CGGTAGTTTG', 'TGGTTTTTGC', 'ACGGTTATCG', 'CTGGTATCC'], 'Motif_ID': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 3, 4, 4, 4], 'File_Name': ['Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada', 'Ada']}\n"
     ]
    }
   ],
   "source": [
    "meme_site_pattern = r'(?P<seq_id>\\d+-\\d+-(?:forward|reverse))\\s*(?P<start_number>\\d+)\\s+\\S+\\s+(?P<site>\\S+)\\s+\\S+\\s+\\S+'\n",
    "# meme_site_pattern = r'(?P<site_id>\\S+)\\s+(?P<start_number>\\d+)\\s+\\S+\\s+(?P<motif_sequence>\\S+)\\s+\\S+\\s+\\S+'\n",
    "meme_site_dict = {'Sequence_ID': [],\n",
    "                  'Site': [],\n",
    "                  'Starting_Point': [],\n",
    "                  'Score': [],\n",
    "                  'Width': [],\n",
    "                  'File_Name': []\n",
    "                  }\n",
    "for i, site in enumerate(meme_sites):\n",
    "    print(site[0])\n",
    "    print(site[1])\n",
    "    # sites_per_motif = re.findall(meme_site_pattern, site[1])\n",
    "    sites_per_motif = re.finditer(meme_site_pattern, site[1])\n",
    "    print(sites_per_motif)\n",
    "    for j, match in enumerate(sites_per_motif):\n",
    "        meme_site_dict['Sequence_ID'].append(match.group('seq_id'))\n",
    "        meme_site_dict['Score'].append(j)\n",
    "        meme_site_dict['Starting_Point'].append(int(match.group('start_number')))\n",
    "        meme_site_dict['Site'].append(match.group('site'))\n",
    "        meme_site_dict['Width'].append(i)\n",
    "        meme_site_dict['File_Name'].append('Ada')\n",
    "\n",
    "print(meme_site_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'meme_site_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_43812/650998269.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mmeme_site_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDataFrame\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmeme_site_dict\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mmeme_site_df\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'meme_site_dict' is not defined"
     ]
    }
   ],
   "source": [
    "meme_site_df = pd.DataFrame(meme_site_dict)\n",
    "meme_site_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/daphne/.local/share/JetBrains/PyCharm2020.3/python/helpers-pro/jupyter_debug/pydev_jupyter_utils.py\", line 69, in attach_to_debugger\n",
      "    debugger.prepare_to_run(enable_tracing_from_start=False)\n",
      "TypeError: prepare_to_run() got an unexpected keyword argument 'enable_tracing_from_start'\n",
      "Failed to connect to target debugger.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_43812/3828335559.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     80\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mresults_df\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     81\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 82\u001B[0;31m \u001B[0mparse_meme_files\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     83\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     84\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_43812/3828335559.py\u001B[0m in \u001B[0;36mparse_meme_files\u001B[0;34m()\u001B[0m\n\u001B[1;32m     72\u001B[0m         \u001B[0mname\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mfilename\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msplit\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'_'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     73\u001B[0m         \u001B[0mmeme_motif_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparse_meme_motif\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmeme_motif_info\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 74\u001B[0;31m         \u001B[0mmeme_sites_df\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparse_meme_sites\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmeme_sites\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmeme_motif_df\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mname\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     75\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     76\u001B[0m         \u001B[0mresults_list\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmeme_sites_df\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/ipykernel_43812/3828335559.py\u001B[0m in \u001B[0;36mparse_meme_sites\u001B[0;34m(sites_info, motif_df, filename)\u001B[0m\n\u001B[1;32m     45\u001B[0m             \u001B[0mmeme_site_dict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'Starting_Point'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmatch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroup\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'start_number'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     46\u001B[0m             \u001B[0mmeme_site_dict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'Site'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmatch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgroup\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'site'\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 47\u001B[0;31m             \u001B[0mmeme_site_dict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'Width'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmotif_df\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'Width'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mloc\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mmotif_index\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     48\u001B[0m             \u001B[0mmeme_site_dict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'File_Name'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mappend\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilename\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     49\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/site-packages/pandas/core/indexing.py\u001B[0m in \u001B[0;36m__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   1071\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1072\u001B[0m             \u001B[0mmaybe_callable\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mcom\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_if_callable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1073\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_getitem_axis\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmaybe_callable\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1074\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1075\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_is_scalar_access\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0mtuple\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/site-packages/pandas/core/indexing.py\u001B[0m in \u001B[0;36m_getitem_axis\u001B[0;34m(self, key, axis)\u001B[0m\n\u001B[1;32m   1299\u001B[0m                     \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Cannot index with multidimensional key\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1300\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1301\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_getitem_iterable\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1302\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1303\u001B[0m             \u001B[0;31m# nested tuple slicing\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/site-packages/pandas/core/indexing.py\u001B[0m in \u001B[0;36m_getitem_iterable\u001B[0;34m(self, key, axis)\u001B[0m\n\u001B[1;32m   1237\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1238\u001B[0m         \u001B[0;31m# A collection of keys\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1239\u001B[0;31m         \u001B[0mkeyarr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_listlike_indexer\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1240\u001B[0m         return self.obj._reindex_with_indexers(\n\u001B[1;32m   1241\u001B[0m             \u001B[0;34m{\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m:\u001B[0m \u001B[0;34m[\u001B[0m\u001B[0mkeyarr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindexer\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m}\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mcopy\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mallow_dups\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/site-packages/pandas/core/indexing.py\u001B[0m in \u001B[0;36m_get_listlike_indexer\u001B[0;34m(self, key, axis)\u001B[0m\n\u001B[1;32m   1430\u001B[0m         \u001B[0maxis_name\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mobj\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_axis_name\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0maxis\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1431\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1432\u001B[0;31m         \u001B[0mkeyarr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0max\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_get_indexer_strict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0maxis_name\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1433\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1434\u001B[0m         \u001B[0;32mreturn\u001B[0m \u001B[0mkeyarr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindexer\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.pyenv/versions/3.9.1/lib/python3.9/site-packages/pandas/core/indexes/base.py\u001B[0m in \u001B[0;36m_get_indexer_strict\u001B[0;34m(self, key, axis_name)\u001B[0m\n\u001B[1;32m   6064\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_index_as_unique\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6065\u001B[0m             \u001B[0mindexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mget_indexer_for\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeyarr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 6066\u001B[0;31m             \u001B[0mkeyarr\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mreindex\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeyarr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   6067\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   6068\u001B[0m             \u001B[0mkeyarr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mindexer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mnew_indexer\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reindex_non_unique\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mkeyarr\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "def parse_meme_motif(motif_info, filename):\n",
    "    meme_dict = {'File_name': [],\n",
    "             'Motif_ID': [],\n",
    "             'Width': [],\n",
    "             'Score': [],\n",
    "             'Sites': [],\n",
    "             'con': []\n",
    "             }\n",
    "    for i, match in enumerate(motif_info):\n",
    "        # print(match)\n",
    "        meme_dict['File_name'].append(filename)\n",
    "        meme_dict['Motif_ID'].append(int(match.group('index')))\n",
    "        meme_dict['Width'].append(int(match.group('width')))\n",
    "        meme_dict['Score'].append(float(match.group('evalue')))\n",
    "        meme_dict['Sites'].append(int(match.group('sites')))\n",
    "        meme_dict['con'].append(match.group('motif'))\n",
    "    meme_motif_df = pd.DataFrame(meme_dict)\n",
    "    # meme_motif_df.sort_values(axis=0, by='Score', inplace=True, ascending=False)\n",
    "    return meme_motif_df\n",
    "\n",
    "def parse_meme_sites(sites_info, motif_df, filename):\n",
    "    meme_site_pattern = r'(?P<seq_id>\\d+-\\d+-(?:forward|reverse))\\s*(?P<start_number>\\d+)\\s+\\S+\\s+(?P<site>\\S+)\\s+\\S+\\s+\\S+'\n",
    "    # meme_site_pattern = r'(?P<site_id>\\S+)\\s+(?P<start_number>\\d+)\\s+\\S+\\s+(?P<motif_sequence>\\S+)\\s+\\S+\\s+\\S+'\n",
    "    meme_site_dict = {'Sequence_ID': [],\n",
    "                      'Site': [],\n",
    "                      'Starting_Point': [],\n",
    "                      'Score': [],\n",
    "                      'Width': [],\n",
    "                      'File_Name': []\n",
    "                      }\n",
    "\n",
    "    for i, site in enumerate(sites_info):\n",
    "        # print(site[0])\n",
    "        # print(site[1])\n",
    "        # sites_per_motif = re.findall(meme_site_pattern, site[1])\n",
    "        motif_mask = motif_df['Motif_ID'] == site[0]\n",
    "        motif_index = motif_df[motif_mask].index\n",
    "\n",
    "        sites_per_motif = re.finditer(meme_site_pattern, site[1])\n",
    "        # print(sites_per_motif)\n",
    "        for j, match in enumerate(sites_per_motif):\n",
    "            meme_site_dict['Sequence_ID'].append(match.group('seq_id'))\n",
    "            meme_site_dict['Score'].append(float(motif_df['Score'].loc[motif_index]))\n",
    "            meme_site_dict['Starting_Point'].append(int(match.group('start_number')))\n",
    "            meme_site_dict['Site'].append(match.group('site'))\n",
    "            meme_site_dict['Width'].append(int(motif_df['Width'].loc[motif_index]))\n",
    "            meme_site_dict['File_Name'].append(filename)\n",
    "\n",
    "    meme_site_df = pd.DataFrame(meme_site_dict)\n",
    "    return meme_site_df\n",
    "\n",
    "\n",
    "\n",
    "def parse_meme_files():\n",
    "    meme_dir = os.path.join(os.getcwd(), 'Results/MEME')\n",
    "    files = os.listdir(meme_dir)\n",
    "    filtered_files = list(filter(lambda name: name if name.find('10') == -1 else '', files))\n",
    "    print(len(filtered_files))\n",
    "\n",
    "    meme_motif_pattern = r'MOTIF\\s+(?P<motif>\\w+)\\s+MEME-(?P<index>\\d)\\s+width\\s+=\\s+(?P<width>\\d+)\\s+sites\\s+=\\s+(?P<sites>\\d+).+E-value\\s*=\\s*(?P<evalue>\\d+(?:\\.\\d+)?(?:e[+-]?\\d+)?)'\n",
    "    sites_pattern = r'MEME-(\\d+) sites sorted by position p-value\\n(?:.*\\n){3}((?:(?!-+).*\\n)*)'\n",
    "\n",
    "    results_list = []\n",
    "    for filename in filtered_files:\n",
    "        with open(os.path.join(meme_dir, filename), 'r') as file:\n",
    "            meme_output = file.read()\n",
    "\n",
    "        meme_motif_info = re.finditer(meme_motif_pattern, meme_output)\n",
    "        meme_sites = re.findall(sites_pattern, meme_output)\n",
    "\n",
    "        name = filename.split('_')[0]\n",
    "        meme_motif_df = parse_meme_motif(meme_motif_info, name)\n",
    "        meme_sites_df = parse_meme_sites(meme_sites, meme_motif_df, name)\n",
    "\n",
    "        results_list.append(meme_sites_df)\n",
    "\n",
    "\n",
    "    results_df = pd.concat(results_list, ignore_index=True)\n",
    "    return results_df\n",
    "\n",
    "parse_meme_files()\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}