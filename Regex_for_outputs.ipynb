{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **All Folders Directories**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bioprospector', 'MDScan', 'MotifSampler', 'Streme', 'MEME']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "direcrory_of_folders = 'Results/'\n",
    "folders = [folder for folder in os.listdir(direcrory_of_folders) if os.path.isdir(os.path.join(direcrory_of_folders, folder))]\n",
    "folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_the_files(path):\n",
    "    txt_files = [file for file in os.listdir(path) if file.endswith(\".txt\")]\n",
    "    only_results = []\n",
    "    for file in txt_files:\n",
    "        if '_' in file:\n",
    "            name_parts = file.split(\"_\")\n",
    "            if len(name_parts) > 1:\n",
    "                name = name_parts[0]\n",
    "                only_results.append(name)\n",
    "    name_counts = Counter(only_results)\n",
    "    unique_names = [name for name, count in name_counts.items() if count > 1] \n",
    "    return  unique_names "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **For MDScan**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the MDscan output file\n",
    "# with open('Results/MDScan/Ada_1.txt', 'r') as file:\n",
    "#     mdscan_output = file.read()\n",
    "directory_of_files = 'Results/MDScan/'\n",
    "\n",
    "# Extract the motifs using regex\n",
    "motif_pattern = r\"Motif\\s+(\\d+):\\s+Wid\\s+(\\d+);\\s+Score\\s+([\\d.]+);\\s+Sites\\s+(\\d+);\\s+Con\\s+([ACGT]+);\\s+RCon\\s+([ACGT]+)\"\n",
    "# motif_info = re.findall(motif_pattern, mdscan_output)\n",
    "\n",
    "# Extract the site information using regex\n",
    "site_pattern = r\">(\\d+-\\d+-(?:forward|reverse))\\s+Len\\s+\\d+\\s+Site\\s+#(\\d+)\\s+([fr])\\s+(\\d+)\\n([ACGT]+)\"\n",
    "# site_info = re.findall(site_pattern, mdscan_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The return_the_files function stores all the unique names of the .txt files except the background.txt file."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The get_the_motifs and get_site_info functions creates a dataframes with vital informations of the motif_info's and the site_info's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_the_motifs_MD(motif_info, file_name):\n",
    "    motifs = {}\n",
    "\n",
    "    for motif_match in motif_info:\n",
    "        motif = {\n",
    "            'File_name': file_name,\n",
    "            'Motif_ID': motif_match[0],\n",
    "            'Width': motif_match[1],\n",
    "            'Score': motif_match[2],\n",
    "            'Sites': motif_match[3],\n",
    "            'con': motif_match[4],\n",
    "            'rcon': motif_match[5]\n",
    "        }\n",
    "        motif_id = motif_match[0]\n",
    "\n",
    "        if motif_id in motifs:\n",
    "            motifs[motif_id].update(motif)  # Merge with existing motif dictionary\n",
    "        else:\n",
    "            motifs[motif_id] = motif\n",
    "\n",
    "    # Convert the motifs dictionary into a DataFrame\n",
    "    df = pd.DataFrame.from_dict(motifs, orient='index')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_site_info(site_info, motif_info, file_name):\n",
    "    data = []\n",
    "    motif_id = 0  # Initial motif ID\n",
    "    initial_position = site_info[0][0]  # Initial position\n",
    "\n",
    "    for site in site_info:\n",
    "        site_id, site_number, _, starting_point, motif_sequence = site\n",
    "\n",
    "        if site_number == '1' and site_id == initial_position:\n",
    "            motif_id += 1\n",
    "            # initial_position = site_id\n",
    "\n",
    "        data.append([site_id, site_number, starting_point, motif_sequence, motif_id, file_name])\n",
    "\n",
    "    columns = ['Site_ID', 'Site_number', 'Starting_Point', 'Motif_Sequence', 'Motif_ID', 'File_Name']\n",
    "    df_info = pd.DataFrame(data, columns=columns)\n",
    "    return df_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_mdscan_output(directory_of_files):\n",
    "    names = return_the_files(directory_of_files)\n",
    "    motif_dfs = []\n",
    "    site_dfs = []\n",
    "\n",
    "    for name in names:\n",
    "        file_paths = [file for file in os.listdir(directory_of_files) if file.startswith(f\"{name}_\")]\n",
    "\n",
    "        for file_path in file_paths:\n",
    "            with open(os.path.join(directory_of_files, file_path), 'r') as file:\n",
    "                mdscan_output = file.read()\n",
    "            \n",
    "            motif_info = re.findall(motif_pattern, mdscan_output)\n",
    "            df_motif = get_the_motifs_MD(motif_info, name)\n",
    "            motif_dfs.append(df_motif)\n",
    "            \n",
    "            site_info = re.findall(site_pattern, mdscan_output)\n",
    "            df_site = get_site_info(site_info, motif_info, name)\n",
    "            site_dfs.append(df_site)\n",
    "\n",
    "    motif_df = pd.concat(motif_dfs, ignore_index=True)\n",
    "    site_df = pd.concat(site_dfs, ignore_index=True)\n",
    "    \n",
    "    site_df['Site_number'] = pd.to_numeric(site_df['Site_number'])\n",
    "    site_df['Motif_ID'] = pd.to_numeric(site_df['Motif_ID'])\n",
    "    site_df['Starting_Point'] = pd.to_numeric(site_df['Starting_Point'])\n",
    "    motif_df['Motif_ID'] = pd.to_numeric(motif_df['Motif_ID'])\n",
    "    motif_df['Sites'] = pd.to_numeric(motif_df['Sites'])\n",
    "    motif_df['Score'] = pd.to_numeric(motif_df['Score'])\n",
    "    motif_df['Width'] = pd.to_numeric(motif_df['Width'])\n",
    "    \n",
    "    return motif_df, site_df\n",
    "\n",
    "# Usage example\n",
    "motif_df_MD, site_df_MD = process_mdscan_output(directory_of_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File_name</th>\n",
       "      <th>Motif_ID</th>\n",
       "      <th>Width</th>\n",
       "      <th>Score</th>\n",
       "      <th>Sites</th>\n",
       "      <th>con</th>\n",
       "      <th>rcon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ada</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>1.795</td>\n",
       "      <td>14</td>\n",
       "      <td>CGGAACCGCTGGCGG</td>\n",
       "      <td>CCGCCAGCGGTTCCG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ada</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1.777</td>\n",
       "      <td>16</td>\n",
       "      <td>CCGGAAACGATGGCG</td>\n",
       "      <td>CGCCATCGTTTCCGG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ada</td>\n",
       "      <td>3</td>\n",
       "      <td>15</td>\n",
       "      <td>1.764</td>\n",
       "      <td>16</td>\n",
       "      <td>GGAAGCGCTGGCGGC</td>\n",
       "      <td>GCCGCCAGCGCTTCC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ada</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>1.754</td>\n",
       "      <td>19</td>\n",
       "      <td>CGCCGCTGGCGGCTG</td>\n",
       "      <td>CAGCCGCCAGCGGCG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ada</td>\n",
       "      <td>5</td>\n",
       "      <td>15</td>\n",
       "      <td>1.749</td>\n",
       "      <td>15</td>\n",
       "      <td>TATCCGTGACGGTGA</td>\n",
       "      <td>TCACCGTCACGGATA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  File_name  Motif_ID  Width  Score  Sites              con             rcon\n",
       "0       Ada         1     15  1.795     14  CGGAACCGCTGGCGG  CCGCCAGCGGTTCCG\n",
       "1       Ada         2     15  1.777     16  CCGGAAACGATGGCG  CGCCATCGTTTCCGG\n",
       "2       Ada         3     15  1.764     16  GGAAGCGCTGGCGGC  GCCGCCAGCGCTTCC\n",
       "3       Ada         4     15  1.754     19  CGCCGCTGGCGGCTG  CAGCCGCCAGCGGCG\n",
       "4       Ada         5     15  1.749     15  TATCCGTGACGGTGA  TCACCGTCACGGATA"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "motif_df_MD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Site_ID</th>\n",
       "      <th>Site_number</th>\n",
       "      <th>Starting_Point</th>\n",
       "      <th>Motif_Sequence</th>\n",
       "      <th>Motif_ID</th>\n",
       "      <th>File_Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>209398-209425-forward</td>\n",
       "      <td>1</td>\n",
       "      <td>151</td>\n",
       "      <td>AAGCGCCGCTGGCGG</td>\n",
       "      <td>1</td>\n",
       "      <td>Ada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>209398-209425-forward</td>\n",
       "      <td>2</td>\n",
       "      <td>258</td>\n",
       "      <td>CGCCATCGCTTCCGG</td>\n",
       "      <td>1</td>\n",
       "      <td>Ada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>209398-209425-forward</td>\n",
       "      <td>3</td>\n",
       "      <td>166</td>\n",
       "      <td>CTGAAGCGATGGGTA</td>\n",
       "      <td>1</td>\n",
       "      <td>Ada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>209398-209425-forward</td>\n",
       "      <td>4</td>\n",
       "      <td>229</td>\n",
       "      <td>CGGAACCACTGGGTG</td>\n",
       "      <td>1</td>\n",
       "      <td>Ada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>209398-209425-forward</td>\n",
       "      <td>5</td>\n",
       "      <td>259</td>\n",
       "      <td>CGGAAGCGATGGCGG</td>\n",
       "      <td>1</td>\n",
       "      <td>Ada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Site_ID  Site_number  Starting_Point   Motif_Sequence  \\\n",
       "0  209398-209425-forward            1             151  AAGCGCCGCTGGCGG   \n",
       "1  209398-209425-forward            2             258  CGCCATCGCTTCCGG   \n",
       "2  209398-209425-forward            3             166  CTGAAGCGATGGGTA   \n",
       "3  209398-209425-forward            4             229  CGGAACCACTGGGTG   \n",
       "4  209398-209425-forward            5             259  CGGAAGCGATGGCGG   \n",
       "\n",
       "   Motif_ID File_Name  \n",
       "0         1       Ada  \n",
       "1         1       Ada  \n",
       "2         1       Ada  \n",
       "3         1       Ada  \n",
       "4         1       Ada  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "site_df_MD.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **For Bioprospector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "Bioproepector_path = 'Results/Bioprospector/'  # Replace with the actual directory path\n",
    "motif_pattern = r'Motif\\s+#(\\d+):\\s+\\((\\w+/\\w+)\\)\\n\\*+\\nWidth \\((\\d+), \\d+\\);\\s+Gap \\[\\d+, \\d+\\];\\s+MotifScore (\\d+\\.\\d+);\\s+Sites (\\d+)'\n",
    "site_pattern = r'>(\\d+-\\d+-\\w+)\\s+len\\s\\d+\\s+site\\s+#(\\d+)\\s+(\\w+)\\s+(\\d+)\\n(\\w+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_the_motifs_BP(motif_info, file_name):\n",
    "    motifs = {}\n",
    "\n",
    "    for motif_match in motif_info:\n",
    "        motif_id = motif_match[0]\n",
    "        con, rcon = motif_match[1].split('/')\n",
    "        width = motif_match[2]\n",
    "        score = motif_match[3]\n",
    "        sites = motif_match[4]\n",
    "\n",
    "        motif = {\n",
    "            'File_name': file_name,\n",
    "            'Motif_ID': motif_id,\n",
    "            'Width': width,\n",
    "            'Score': score,\n",
    "            'Sites': sites,\n",
    "            'con': con,\n",
    "            'rcon': rcon\n",
    "        }\n",
    "\n",
    "        if motif_id in motifs:\n",
    "            motifs[motif_id].update(motif)  # Merge with existing motif dictionary\n",
    "        else:\n",
    "            motifs[motif_id] = motif\n",
    "\n",
    "    # Convert the motifs dictionary into a DataFrame\n",
    "    df = pd.DataFrame.from_dict(motifs, orient='index')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_Bioprospector_output(directory_of_files):\n",
    "    names = return_the_files(directory_of_files)\n",
    "    motif_dfs = []\n",
    "    site_dfs = []\n",
    "\n",
    "    for name in names:\n",
    "        file_paths = [file for file in os.listdir(directory_of_files) if file.startswith(f\"{name}_\")]\n",
    "\n",
    "        for file_path in file_paths:\n",
    "            with open(os.path.join(directory_of_files, file_path), 'r') as file:\n",
    "                mdscan_output = file.read()\n",
    "            \n",
    "            motif_info = re.findall(motif_pattern, mdscan_output)\n",
    "            df_motif = get_the_motifs_BP(motif_info, name)\n",
    "            motif_dfs.append(df_motif)\n",
    "            \n",
    "            site_info = re.findall(site_pattern, mdscan_output)\n",
    "            df_site = get_site_info(site_info, motif_info, name)\n",
    "            site_dfs.append(df_site)\n",
    "\n",
    "    motif_df = pd.concat(motif_dfs, ignore_index=True)\n",
    "    site_df = pd.concat(site_dfs, ignore_index=True)\n",
    "    \n",
    "    site_df['Site_number'] = pd.to_numeric(site_df['Site_number'])\n",
    "    site_df['Motif_ID'] = pd.to_numeric(site_df['Motif_ID'])\n",
    "    site_df['Starting_Point'] = pd.to_numeric(site_df['Starting_Point'])\n",
    "    motif_df['Motif_ID'] = pd.to_numeric(motif_df['Motif_ID'])\n",
    "    motif_df['Sites'] = pd.to_numeric(motif_df['Sites'])\n",
    "    motif_df['Score'] = pd.to_numeric(motif_df['Score'])\n",
    "    motif_df['Width'] = pd.to_numeric(motif_df['Width'])\n",
    "    \n",
    "    return motif_df, site_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_df_BP, site_df_BP = process_Bioprospector_output(Bioproepector_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **For MotifSampler**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Results/MotifSampler/Ada_1.txt', 'r') as file:\n",
    "    text = file.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the patterns\n",
    "pattern_id_ll = re.compile(r'^#id: (?P<id>\\S+).*ll: (?P<ll>\\S+)')\n",
    "pattern_sites = re.compile(r'id \"(?P<id>\\S+)\"; site \"(?P<site>\\S+)\";')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id: box_1_1_nnTnTnnGTGAnGGT, ll: 28.81, sites: ['GTTATCGGTGAAGGT', 'GGTATCCGTGACGGT', 'TTTTTGCGTGATGGT']\n",
      "id: box_1_2_TCACCGTCACssrkA, ll: 25.89, sites: ['TCACCGTAACCCGGA', 'CCACCTTCACCGATA', 'TTACCGTCACGCATG', 'TCACCGGCATGGGGA']\n",
      "id: box_2_3_TAAmskTTATnCTGA, ll: 28.52, sites: ['TAACGTTTATGCTGA', 'TAAACGTTATTCAGA', 'TAAAGGCTATCCTTA', 'TAGCCTTTAGGCTGC']\n",
      "id: box_3_1_GnTnnCnGnGAnGGn, ll: 28.9, sites: ['GTTATCGGTGAAGGT', 'GGTATCCGTGACGGT', 'GTTCGCCGGGAAGGG']\n",
      "id: box_3_2_AAnnnnGnCGnCnAA, ll: 26.91, sites: ['AAGAGCGCCGACAAA', 'AATGCCGACGGCGAA', 'AAGACGGACGGCAAA']\n",
      "id: box_5_1_kyTTCGyTnTCArCG, ll: 25.01, sites: ['TCGTCGTTATCAGCG', 'GTTGCGCTTTCAACG', 'GCTTCCTTGTCAGCG', 'TTTTCGCTGACAAGG']\n",
      "id: box_5_2_TnysCGTGmCGGTGA, ll: 27.75, sites: ['TCCCCATGCCGGTGA', 'CATGCGTGACGGTAA', 'TATCCGTGACGGTGA', 'TACTCGGGCCGGAGA', 'TTTGCGTGATGGTGA']\n",
      "id: box_5_3_TAAmskTTATnCTGA, ll: 28.5, sites: ['TAACGTTTATGCTGA', 'TAAACGTTATTCAGA', 'TAAAGGCTATCCTTA', 'TAGCCTTTAGGCTGC']\n"
     ]
    }
   ],
   "source": [
    "# Initialize the dictionary to store the results\n",
    "data = {}\n",
    "\n",
    "# Split the text into lines and process each line\n",
    "for line in text.split('\\n'):\n",
    "    match_id_ll = pattern_id_ll.match(line)\n",
    "    match_sites = pattern_sites.search(line)\n",
    "\n",
    "    # If the line matches the id_ll pattern, store the id and ll in the dictionary\n",
    "    if match_id_ll:\n",
    "        id = match_id_ll.group('id')\n",
    "        ll = float(match_id_ll.group('ll'))\n",
    "        data[id] = {'ll': ll, 'sites': []}\n",
    "\n",
    "    # If the line matches the sites pattern, append the site to the list of sites for the appropriate id\n",
    "    if match_sites:\n",
    "        id = match_sites.group('id')\n",
    "        site = match_sites.group('site')\n",
    "        data[id]['sites'].append(site)\n",
    "\n",
    "# Print the results\n",
    "for id, info in data.items():\n",
    "    print(f\"id: {id}, ll: {info['ll']}, sites: {info['sites']}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## **For MEME**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [],
   "source": [
    "def parse_meme_motif(motif_info, filename):\n",
    "    meme_dict = {'File_name': [],\n",
    "             'Motif_ID': [],\n",
    "             'Width': [],\n",
    "             'Score': [],\n",
    "             'Sites': [],\n",
    "             'con': []\n",
    "             }\n",
    "    for i, match in enumerate(motif_info):\n",
    "        # print(match)\n",
    "        meme_dict['File_name'].append(filename)\n",
    "        meme_dict['Motif_ID'].append(int(match.group('index')))\n",
    "        meme_dict['Width'].append(int(match.group('width')))\n",
    "        meme_dict['Score'].append(float(match.group('evalue')))\n",
    "        meme_dict['Sites'].append(int(match.group('sites')))\n",
    "        meme_dict['con'].append(match.group('motif'))\n",
    "    meme_motif_df = pd.DataFrame(meme_dict)\n",
    "    # meme_motif_df.sort_values(axis=0, by='Score', inplace=True, ascending=False)\n",
    "    return meme_motif_df\n",
    "\n",
    "def parse_meme_sites(sites_info, motif_df, filename):\n",
    "    meme_site_pattern = r'(?P<seq_id>\\d+-\\d+-(?:forward|reverse))\\s*(?P<start_number>\\d+)\\s+\\S+\\s+(?P<site>\\S+)\\s+\\S+\\s+\\S+'\n",
    "    # meme_site_pattern = r'(?P<site_id>\\S+)\\s+(?P<start_number>\\d+)\\s+\\S+\\s+(?P<motif_sequence>\\S+)\\s+\\S+\\s+\\S+'\n",
    "    meme_site_dict = {'Sequence_ID': [],\n",
    "                      'Site': [],\n",
    "                      'Starting_Point': [],\n",
    "                      'Score': [],\n",
    "                      'Width': [],\n",
    "                      'File_Name': []\n",
    "                      }\n",
    "\n",
    "    for i, site in enumerate(sites_info):\n",
    "        # print(site[0])\n",
    "        # print(site[1])\n",
    "        # sites_per_motif = re.findall(meme_site_pattern, site[1])\n",
    "        motif_mask = motif_df['Motif_ID'] == int(site[0])\n",
    "        motif_index = motif_df[motif_mask].index\n",
    "\n",
    "        sites_per_motif = re.finditer(meme_site_pattern, site[1])\n",
    "        # print(sites_per_motif)\n",
    "        for j, match in enumerate(sites_per_motif):\n",
    "            meme_site_dict['Sequence_ID'].append(match.group('seq_id'))\n",
    "            meme_site_dict['Score'].append(int(motif_df['Score'].loc[motif_index]))\n",
    "            meme_site_dict['Starting_position'].append(int(match.group('start_number')))\n",
    "            meme_site_dict['Site'].append(match.group('site'))\n",
    "            meme_site_dict['Width'].append(int(motif_df['Width'].loc[motif_index]))\n",
    "            meme_site_dict['File_name'].append(filename)\n",
    "\n",
    "    meme_site_df = pd.DataFrame(meme_site_dict)\n",
    "    return meme_site_df\n",
    "\n",
    "\n",
    "\n",
    "def parse_meme_files():\n",
    "    meme_dir = os.path.join(os.getcwd(), 'Results/MEME')\n",
    "    files = os.listdir(meme_dir)\n",
    "    filtered_files = list(filter(lambda name: name if name.find('10') == -1 else '', files))\n",
    "    print(len(filtered_files))\n",
    "\n",
    "    meme_motif_pattern = r'MOTIF\\s+(?P<motif>\\w+)\\s+MEME-(?P<index>\\d)\\s+width\\s+=\\s+(?P<width>\\d+)\\s+sites\\s+=\\s+(?P<sites>\\d+).+E-value\\s*=\\s*(?P<evalue>\\d+(?:\\.\\d+)?(?:e[+-]?\\d+)?)'\n",
    "    sites_pattern = r'MEME-(\\d+) sites sorted by position p-value\\n(?:.*\\n){3}((?:(?!-+).*\\n)*)'\n",
    "\n",
    "    results_list = []\n",
    "    for filename in filtered_files:\n",
    "        with open(os.path.join(meme_dir, filename), 'r') as file:\n",
    "            meme_output = file.read()\n",
    "\n",
    "        meme_motif_info = re.finditer(meme_motif_pattern, meme_output)\n",
    "        meme_sites = re.findall(sites_pattern, meme_output)\n",
    "\n",
    "        name = filename.split('_')[0]\n",
    "        meme_motif_df = parse_meme_motif(meme_motif_info, name)\n",
    "        meme_sites_df = parse_meme_sites(meme_sites, meme_motif_df, name)\n",
    "\n",
    "        results_list.append(meme_sites_df)\n",
    "\n",
    "\n",
    "    results_df = pd.concat(results_list, ignore_index=True)\n",
    "    return results_df"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610\n"
     ]
    },
    {
     "data": {
      "text/plain": "               Sequence_ID        Site  Starting_Point  Score  Width File_Name\n0  4464895-4464912-reverse  AAGCGCCGCA             140    600      8      PhoP\n1  4464895-4464912-reverse  GTTAGGCTCA             261    600      8      PhoP\n2  4464895-4464912-reverse  AGGAGAATCC             157    600      8      PhoP\n3  1189730-1189747-reverse  ACACTATTTT             252    600      8      PhoP\n4  1906840-1906857-reverse  ATATCCGCTG              51    600      8      PhoP",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sequence_ID</th>\n      <th>Site</th>\n      <th>Starting_Point</th>\n      <th>Score</th>\n      <th>Width</th>\n      <th>File_Name</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4464895-4464912-reverse</td>\n      <td>AAGCGCCGCA</td>\n      <td>140</td>\n      <td>600</td>\n      <td>8</td>\n      <td>PhoP</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4464895-4464912-reverse</td>\n      <td>GTTAGGCTCA</td>\n      <td>261</td>\n      <td>600</td>\n      <td>8</td>\n      <td>PhoP</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4464895-4464912-reverse</td>\n      <td>AGGAGAATCC</td>\n      <td>157</td>\n      <td>600</td>\n      <td>8</td>\n      <td>PhoP</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1189730-1189747-reverse</td>\n      <td>ACACTATTTT</td>\n      <td>252</td>\n      <td>600</td>\n      <td>8</td>\n      <td>PhoP</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1906840-1906857-reverse</td>\n      <td>ATATCCGCTG</td>\n      <td>51</td>\n      <td>600</td>\n      <td>8</td>\n      <td>PhoP</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = parse_meme_files()\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}